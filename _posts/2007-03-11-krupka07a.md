---
title: Incorporating Prior Knowledge on Features into Learning
abstract: In the standard formulation of supervised learning the input is represented
  as a vector of features.  However, in most real-life problems, we also have additional
  information about each of the features.  This information can be represented as
  a set of properties, referred to as meta-features. For instance, in an image recognition
  task, where the features are pixels, the meta-features can be the $(x, y)$ position
  of each pixel. We propose a new learning framework that incorporates meta-features.  In
  this framework we assume that a weight is assigned to each feature, as in linear
  discrimination, and we use the meta-features to define a prior on the weights. This
  prior is based on a Gaussian process and the weights are assumed to be a smooth
  function of the meta-features. Using this framework we derive a practical algorithm
  that improves generalization by using meta-features and discuss the theoretical
  advantages of incorporating them into the learning. We apply our framework to design
  a new kernel for hand-written digit recognition. We obtain higher accuracy with
  lower computational complexity in the primal representation. Finally, we discuss
  the applicability of this framework to biological neural networks.
pdf: http://proceedings.mlr.press/v2/krupka07a/krupka07a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: krupka07a
month: 0
tex_title: Incorporating Prior Knowledge on Features into Learning
firstpage: 227
lastpage: 234
page: 227-234
order: 227
cycles: false
author:
- given: Eyal
  family: Krupka
- given: Naftali
  family: Tishby
date: 2007-03-11
address: San Juan, Puerto Rico
publisher: PMLR
container-title: Proceedings of the Eleventh International Conference on Artificial
  Intelligence and Statistics
volume: '2'
genre: inproceedings
issued:
  date-parts:
  - 2007
  - 3
  - 11
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
