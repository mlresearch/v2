---
title: Local and global sparse Gaussian process approximations
abstract: Gaussian process (GP) models are flexible probabilistic nonparametric models
  for regression, classification and other tasks. Unfortunately they suffer from computational
  intractability for large data sets. Over the past decade there have been many different
  approximations developed to reduce this cost. Most of these can be termed global
  approximations, in that they try to summarize all the training data via a small
  set of support points. A different approach is that of local regression, where many
  local experts account for their own part of space. In this paper we start by investigating
  the regimes in which these different approaches work well or fail. We then proceed
  to develop a new sparse GP approximation which is a combination of both the global
  and local approaches. Theoretically we show that it is derived as a natural extension
  of the framework developed by Qui√±onero Candela and Rasmussen [2005] for n sparse
  GP approximations. We demonstrate the benefits of the combined approximation on
  some 1D examples for illustration, and on some large real-world data sets.
pdf: http://proceedings.mlr.press/v2/snelson07a/snelson07a.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: snelson07a
month: 0
tex_title: Local and global sparse Gaussian process approximations
firstpage: 524
lastpage: 531
page: 524-531
order: 524
cycles: false
author:
- given: Edward
  family: Snelson
- given: Zoubin
  family: Ghahramani
date: 2007-03-11
address: San Juan, Puerto Rico
publisher: PMLR
container-title: Proceedings of the Eleventh International Conference on Artificial
  Intelligence and Statistics
volume: '2'
genre: inproceedings
issued:
  date-parts:
  - 2007
  - 3
  - 11
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
